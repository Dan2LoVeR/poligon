# Находим пары документов с минимальными расстояниями
n_docs = len(documents)
# Получаем количество документов
pairs = []
# Создаем список для хранения пар документов и расстояний между ними

for i in range(n_docs):
    for j in range(i+1, n_docs):
        # Перебираем все уникальные пары документов (чтобы не дублировать)
        pairs.append((i, j, distances[i][j]))
        # Добавляем кортеж (индекс первого, индекс второго, расстояние)

# Сортируем пары по расстоянию
pairs_sorted = sorted(pairs, key=lambda x: x[2])
# Сортируем список пар по третьему элементу кортежа (расстоянию)

# Берем 20-30 минимальных расстояний
min_pairs = pairs_sorted[20:30]
# Выбираем пары с 20-го по 30-е место в отсортированном списке

# Кластеризация (используем метод одиночной связи)
from sklearn.cluster import AgglomerativeClustering
# Импортируем алгоритм иерархической кластеризации

# Выбираем 3 кластера
clustering = AgglomerativeClustering(
    n_clusters=3,          # Количество кластеров
    affinity='precomputed', # Используем предвычисленную матрицу расстояний
    linkage='complete'     # Метод связи (complete - максимальное расстояние между кластерами)
)
clusters = clustering.fit_predict(distances)
# Выполняем кластеризацию на основе матрицы расстояний

print("Принадлежность документов к кластерам:")
print(clusters)
# Выводим массив, где каждому документу соответствует номер кластера